import pandas as pd
import streamlit as st
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_validate 
from time import time
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler


#pip install scikit-learn==1.2.2 !!!!!!!! problema do KNN


nome_metricas=['precision', 'recall', 'accuracy']

st.set_page_config(
    page_title= "Machine Learning",
    page_icon= "üß†",
    layout= "wide",
    initial_sidebar_state= "collapsed",
    menu_items= {
        'About': "Desenvolvido por:\n- Dayvson Moura;\n- Thales Mayrinck"
    }
)


def main():
    header()
    df_processado = preprocessamento()
    df_transformado = transformacao(df_processado)
    df_transformado.to_csv("dataframe_final.csv")
    with st.expander("KNeighborsClassifier"):
        kneighbors(df_processado, df_transformado)
    with st.expander("Naive Bayes"):
        naive_bayes(df_processado, df_transformado)
    with st.expander("√Årvore de Decis√£o"):
        arvore(df_processado, df_transformado)
    st.divider()
        


def header():
    st.header("Machine Learning")
    st.markdown("""
                Esta p√°gina apresenta os modelos de <i>machine learning</i> criados e os seus resultados.            
                """,
                unsafe_allow_html= True)


@st.cache_data
def ler_dataset():
    df = pd.read_csv("./data/covid_no_mexico.csv")
    return df.copy()


def preprocessamento():
    st.markdown("### Pr√©-processamento")
    st.markdown("""
                Nesta etapa foram removidas todas as colunas que julgamos n√£o serem necess√°rias para o Machine Learning.
                """,
                unsafe_allow_html=True)
    df = ler_dataset()
    df = df.drop(["DATA_DE_INGRESSO","DATA_DE_SINTOMAS","DATA_DO_ARQUIVO","DATA_DE_ATUALIZACAO","DATA_DE_OBITO","SETOR","ATRASO","ENTIDADE_UM","ENTIDADE_RES","ENTIDADE_DE_REGISTRO","ENTIDADE","ABR_ENT","ENTIDADE_DE_NASCIMENTO","MUNICIPIO_RES","PA√çS_DE_ORIGEM","PA√çS_DE_NACIONALIDADE","ID_REGISTRO","id","NACIONALIDADE","IDIOMA_IND√çGENA_FALADO"], axis = 1)
    indices_a_remover = np.random.choice(df.index, 253000, replace=False)
    df = df.drop(indices_a_remover)


    if st.checkbox("Mostrar dataset ap√≥s o pr√©-processamento dos dados"):
        st.dataframe(df)
    st.divider()
    

    #falta renomear os valores das colunas
    return df





def transformacao(df):
    st.markdown("### Transforma√ß√£o")
    st.markdown("""
                Nesta etapa, as colunas categ√≥ricas foram transformadas usando a t√©cnica <i>One-Hot Encoding</i> para converter os seus dados em valores num√©ricos. Em seguida, foi realizado o balanceamento dos dados utilizando a t√©cnica <i>SMOTE</i> e a normaliza√ß√£o da coluna IDADE.
                """,
                unsafe_allow_html=True)
    
    colunas_categoricas_multivalor = ['ORIGEM','SEXO','TIPO_DE_PACIENTE','INTUBADO','PNEUMONIA','GRAVIDEZ','DIABETES','EPOC','ASMA','IMUNOSSUPRIMIDO','HIPERTENS√ÉO','OUTRAS_COMORBIDADES','DOEN√áA_CARDIOVASCULAR','OBESIDADE','DOEN√áA_RENAL_CR√îNICA','TABAGISMO','OUTRO_CASO','MIGRANTE','UTI']
    df_transformado = pd.get_dummies(df, columns=colunas_categoricas_multivalor)
    y = df_transformado['RESULTADO'] # R√≥tulos    
    x = df_transformado.drop('RESULTADO', axis = 1) # Features
    X_res, y_res = SMOTE().fit_resample(x, y)
    df_balanceado = pd.DataFrame(X_res, columns=x.columns)
    df_balanceado['RESULTADO'] = y_res
    scaler = StandardScaler()
    vals = df_balanceado[['IDADE']].values
    df_balanceado['IDADE'] = scaler.fit_transform(vals)
    novo_nome_colunas = {'ORIGEM_1': 'USMER', 'ORIGEM_2': 'FORA DE USMER','ORIGEM_3': 'N√ÉO ESPECIFICADO','SEXO_1': 'MULHER', 'SEXO_2': 'HOMEM', 'TIPO_DE_PACIENTE_1': 'AMBULATORIO', 'TIPO_DE_PACIENTE_2': 'HOSPITALIZADO', 'TIPO_DE_PACIENTE_3': 'N√ÉO ESPECIFICADO', 'INTUBADO_1': 'INTUBADO', 'INTUBADO_2': 'N√ÉO INTUBADO', 'INTUBADO_97': 'N√ÉO SE APLICA', 'INTUBADO_99': 'N√ÉO ESPECIFICADO', 'PNEUMONIA_1': 'COM PNEUMONIA', 'PNEUMONIA_2': 'SEM PNEUMONIA', 'PNEUMONIA_99': 'N√ÉO ESPECIFICADO' , 'GRAVIDEZ_1': 'EST√Å GR√ÅVIDA', 'GRAVIDEZ_2': 'N√ÉO EST√Å GR√ÅVIDA','DIABETES_1': 'POSSUI DIABETES', 'DIABETES_2': 'N√ÉO POSSUI DIABETES', 'DIABETES_98': 'SE IGNORA' , 'EPOC_1': 'POSSUI EPOC', 'EPOC_2': 'N√ÉO POSSUI EPOC', 'ASMA_1': 'POSSUI ASMA', 'ASMA_2': 'N√ÉO POSSUI ASMA', 'IMUNOSSUPRIMIDO_1': '√â IMUNOSSUPRIMIDO', 'IMUNOSSUPRIMIDO_2': 'N√ÉO √â IMUNOSSUPRIMIDO','HIPERTENS√ÉO_1': 'POSSUI HIPERTENS√ÉO', 'HIPERTENS√ÉO_2': 'N√ÉO POSSUI HIPERTENS√ÉO','OUTRAS_COMORBIDADES_1': 'POSSUI OUTRAS COMORBIDADES', 'OUTRAS_COMORBIDADES_2': 'N√ÉO POSSUI OUTRAS COMORBIDADES','DOEN√áA_CARDIOVASCULAR_1': 'POSSUI DOEN√áA CARDIOVASCULAR', 'DOEN√áA_CARDIOVASCULAR_2':
    'N√ÉO POSSUI DOEN√áA CARDIOVASCULAR','OBESIDADE_1': 'POSSUI OBESIDADE', 'OBESIDADE_2': 'N√ÉO POSSUI OBESIDADE','DOEN√áA_RENAL_CR√îNICA_1': 'POSSUI DOEN√áA RENAL CR√îNICA', 'DOEN√áA_RENAL_CR√îNICA_2': 'N√ÉO POSSUI DOEN√áA RENAL CR√îNICA','TABAGISMO_1': 'PRATICA O TABAGISMO','TABAGISMO_2': 'N√ÉO PRATICA O TABAGISMO', 'OUTRO_CASO_1': 'TEVE CONTATO COM ALGUEM DIAGNOSTICADO COM COVID 19', 'OUTRO_CASO_2': 'N√ÉO TEVE CONTATO COM ALGUEM DIAGNOSTICADO COM COVID 19', 'MIGRANTE_1': '√â IMIGRANTE', 'MIGRANTE_2': 'N√ÉO √â IMIGRANTE','UTI_1': 'EST√Å NA UTI', 'UTI_2': 'N√ÉO EST√Å NA UTI',}
    df_balanceado.rename(columns=novo_nome_colunas, inplace=True)
    if st.checkbox("Mostrar dataset ap√≥s a transforma√ß√£o dos dados"):
        st.dataframe(df_balanceado)
    st.divider()
    
    return df_balanceado


    

def validacao_cruzada_por_modelo (modelo, dfinicial, dfprocessado):
    df = {'dfinicial': dfinicial, 'dfprocessado':dfprocessado}
    results_final = []
    for df_nome, dataframe in df.items():
        tempo_randomforest=[]
        divisao, rotulos = dataframe.drop('RESULTADO', axis=1), dataframe['RESULTADO']
        resultados={medida: [] for medida in nome_metricas}
        for i in range (5):
            classifier = modelo
            t1=time()
            execucao = cross_validate(classifier, divisao, rotulos, cv=10, scoring=nome_metricas)
            t2=time()
            tempo_randomforest.append(t2-t1)
            mean_results = {'Dataset': df_nome, 'Mean time': np.mean(tempo_randomforest)}
            for medida in nome_metricas:
                resultados[medida].append(np.mean(execucao[f'test_{medida}']))
                mean_results[medida] = np.mean(resultados[medida])
        results_final.append(mean_results)
    return results_final




def kneighbors(dfinicial, dfprocessado):
    st.markdown("""
                
                O K-Nearest Neighbors (KNN) √© um algoritmo de aprendizado de m√°quina supervisionado usado principalmente para tarefas de classifica√ß√£o e regress√£o. Ele se baseia no princ√≠pio de que exemplos semelhantes est√£o pr√≥ximos uns dos outros no espa√ßo de caracter√≠sticas. O KNN classifica um novo exemplo com base na maioria das classes dos seus vizinhos mais pr√≥ximos.
                """, 
                unsafe_allow_html=True)
    st.markdown("K=3")
    classifier = KNeighborsClassifier(n_neighbors=3)
    resultado=validacao_cruzada_por_modelo(classifier, dfinicial=dfinicial, dfprocessado=dfprocessado)
    st.dataframe(resultado[:])
    st.markdown("K=7")
    classifier = KNeighborsClassifier(n_neighbors=7)
    resultado=validacao_cruzada_por_modelo(classifier, dfinicial=dfinicial, dfprocessado=dfprocessado)
    st.dataframe(resultado[:])
    st.markdown("K=10")
    classifier = KNeighborsClassifier(n_neighbors=10)
    resultado=validacao_cruzada_por_modelo(classifier, dfinicial=dfinicial, dfprocessado=dfprocessado)
    st.dataframe(resultado[:])


def naive_bayes(dfinicial, dfprocessado):
    st.markdown("""
                O Naive Bayes √© um algoritmo de aprendizado de m√°quina que usa o Teorema de Bayes para calcular a probabilidade de uma inst√¢ncia pertencer a uma classe espec√≠fica com base nas probabilidades das caracter√≠sticas condicionadas √† classe. Embora fa√ßa a suposi√ß√£o simplificada de independ√™ncia entre as caracter√≠sticas, o Naive Bayes √© eficaz em tarefas de classifica√ß√£o, como filtragem de spam e categoriza√ß√£o de texto, sendo particularmente √∫til em cen√°rios com grandes conjuntos de dados e caracter√≠sticas categ√≥ricas, apesar de suas limita√ß√µes.
                """, 
                unsafe_allow_html=True)
    classifier = GaussianNB()
    resultado=validacao_cruzada_por_modelo(classifier, dfinicial=dfinicial, dfprocessado=dfprocessado)
    st.dataframe(resultado[:])


def arvore(dfinicial, dfprocessado):
    st.markdown("""
                Decision Tree (√Årvore de Decis√£o) √© um algoritmo de aprendizado de m√°quina usado para classifica√ß√£o e regress√£o. Ele divide o conjunto de dados em subconjuntos com base nas caracter√≠sticas para tomar decis√µes em forma de √°rvore. Cada n√≥ representa uma escolha de atributo e cada folha representa uma classe ou valor de sa√≠da. As √°rvores de decis√£o s√£o interpretables e podem ser usadas em uma variedade de dom√≠nios.
                """, 
                unsafe_allow_html=True)
    classifier = DecisionTreeClassifier(random_state=42)
    resultado=validacao_cruzada_por_modelo(classifier, dfinicial=dfinicial, dfprocessado=dfprocessado)
    st.dataframe(resultado[:])


main()